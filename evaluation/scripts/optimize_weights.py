#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æƒé‡ä¼˜åŒ–ï¼šæ‰¾åˆ°BM25å’Œå‘é‡çš„æœ€ä½³é…æ¯”
"""
import sys
sys.path.insert(0, '.')
from test_hybrid_search import *
import json
from pathlib import Path
from collections import defaultdict

def generate_test_queries_from_conversation(conv_file: Path, sample_size: int = 20):
    """
    ä»å¯¹è¯ä¸­è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•æŸ¥è¯¢

    ç­–ç•¥ï¼š
    1. å…³é”®è¯æŸ¥è¯¢ï¼šæå–é«˜é¢‘è¯ä½œä¸ºæŸ¥è¯¢
    2. å®ä½“æŸ¥è¯¢ï¼šæå–äººåã€åœ°ç‚¹ç­‰
    3. çŸ­è¯­æŸ¥è¯¢ï¼šæå–2-3ä¸ªè¯çš„çŸ­è¯­
    """
    with open(conv_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    messages = data['messages']
    conv_name = data['meta']['name']

    # ç»Ÿè®¡è¯é¢‘
    from collections import Counter
    import jieba

    word_counter = Counter()
    phrases = []

    for msg in messages:
        content = msg.get('content', '')
        if not content or len(content) < 2:
            continue

        # åˆ†è¯å¹¶ç»Ÿè®¡
        words = [w for w in jieba.cut(content) if len(w) > 1]
        word_counter.update(words)

        # æå–çŸ­è¯­ï¼ˆ2-4ä¸ªå­—ï¼‰
        for i in range(len(content) - 1):
            phrase = content[i:i+2]
            if len(phrase) == 2 and phrase.strip():
                phrases.append(phrase)

    # ç”Ÿæˆæµ‹è¯•æŸ¥è¯¢
    queries = {
        'keyword': [],  # å…³é”®è¯æŸ¥è¯¢
        'semantic': [], # è¯­ä¹‰æŸ¥è¯¢
        'mixed': []     # æ··åˆæŸ¥è¯¢
    }

    # 1. é«˜é¢‘å…³é”®è¯ï¼ˆæ’é™¤åœç”¨è¯ï¼‰
    stopwords = {'çš„', 'äº†', 'æˆ‘', 'ä½ ', 'æ˜¯', 'åœ¨', 'æœ‰', 'ä¸ª', 'è¿™', 'é‚£',
                 'å°±', 'ä¸', 'è¯´', 'éƒ½', 'ä¹Ÿ', 'å’Œ', 'å¥½', 'å§', 'å•Š', 'å‘¢'}

    for word, count in word_counter.most_common(50):
        if word not in stopwords and len(word) >= 2:
            queries['keyword'].append(word)

    # 2. å¸¸è§çŸ­è¯­
    phrase_counter = Counter(phrases)
    for phrase, count in phrase_counter.most_common(30):
        if count >= 2:  # è‡³å°‘å‡ºç°2æ¬¡
            queries['semantic'].append(phrase)

    # 3. éšæœºé‡‡æ ·å®Œæ•´å¥å­ï¼ˆä½œä¸ºè¯­ä¹‰æŸ¥è¯¢ï¼‰
    import random
    sampled_messages = random.sample(
        [m for m in messages if m.get('content') and len(m['content']) > 10],
        min(10, len(messages))
    )
    for msg in sampled_messages:
        content = msg['content'][:30]  # å–å‰30å­—
        queries['mixed'].append(content)

    # é™åˆ¶æ•°é‡
    return {
        'conversation': conv_name,
        'file': str(conv_file),
        'keyword': queries['keyword'][:10],
        'semantic': queries['semantic'][:10],
        'mixed': queries['mixed'][:5]
    }

def test_weight_configuration(
    vector_store: HybridVectorStore,
    embedding_client,
    test_queries: dict,
    bm25_weight: float
) -> dict:
    """æµ‹è¯•å•ä¸ªæƒé‡é…ç½®"""

    results = {
        'bm25_weight': bm25_weight,
        'vector_weight': 1 - bm25_weight,
        'queries': [],
        'metrics': {}
    }

    all_scores_diff = []

    for query_type in ['keyword', 'semantic', 'mixed']:
        for query in test_queries.get(query_type, []):
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_emb = embedding_client.get_embeddings([query])[0]

            # æ··åˆæ£€ç´¢
            search_results = vector_store.hybrid_search(
                query_content_embedding=query_emb,
                query_text=query,
                top_k=5,
                bm25_weight=bm25_weight,
                vector_weight=1-bm25_weight
            )

            if search_results:
                top1_score = search_results[0]['score']
                top3_score = search_results[2]['score'] if len(search_results) >= 3 else 0
                score_diff = top1_score - top3_score
                all_scores_diff.append(score_diff)

                results['queries'].append({
                    'query': query,
                    'type': query_type,
                    'top1_score': top1_score,
                    'top3_score': top3_score,
                    'score_diff': score_diff,
                    'bm25_score': search_results[0]['bm25_score'],
                    'vector_score': search_results[0]['vector_score']
                })

    # è®¡ç®—æŒ‡æ ‡
    if all_scores_diff:
        results['metrics'] = {
            'avg_score_diff': sum(all_scores_diff) / len(all_scores_diff),
            'min_score_diff': min(all_scores_diff),
            'max_score_diff': max(all_scores_diff),
            'total_queries': len(all_scores_diff)
        }

    return results

def optimize_weights_for_conversations(conv_files: list, output_file: str = "weight_optimization_results.json"):
    """ä¸ºå¤šä¸ªå¯¹è¯ä¼˜åŒ–æƒé‡"""

    print("="*80)
    print("æƒé‡ä¼˜åŒ–ï¼šå¯»æ‰¾BM25å’Œå‘é‡çš„æœ€ä½³é…æ¯”")
    print("="*80)

    # åˆå§‹åŒ–
    embedding_client = GoogleEmbeddingClient()

    # æƒé‡å€™é€‰
    weight_candidates = [0.5, 0.6, 0.7, 0.8, 0.9]

    all_results = {
        'conversations': [],
        'weight_comparison': defaultdict(lambda: {'total_score_diff': 0, 'count': 0})
    }

    # ä¸ºæ¯ä¸ªå¯¹è¯æµ‹è¯•
    for conv_file in conv_files:
        print(f"\n{'='*80}")
        print(f"å¤„ç†å¯¹è¯: {conv_file.name}")
        print(f"{'='*80}")

        # 1. ç”Ÿæˆembeddingï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        pkl_file = conv_file.parent / f"{conv_file.stem}_dual.pkl"

        if not pkl_file.exists():
            print(f"[INFO] ç”ŸæˆåŒå‘é‡...")
            from test_embedding_simple import VectorKnowledgeBasePipeline
            pipeline = VectorKnowledgeBasePipeline()
            pipeline.process_conversation(conv_file)
            pipeline.vector_store.save(str(pkl_file))

        # 2. åŠ è½½å‘é‡åº“
        print(f"[INFO] åŠ è½½å‘é‡åº“...")
        vector_store = HybridVectorStore(dimension=768)
        vector_store.load(str(pkl_file))
        vector_store.build_bm25_index()

        # 3. ç”Ÿæˆæµ‹è¯•æŸ¥è¯¢
        print(f"[INFO] ç”Ÿæˆæµ‹è¯•æŸ¥è¯¢...")
        test_queries = generate_test_queries_from_conversation(conv_file)

        print(f"[INFO] æµ‹è¯•æŸ¥è¯¢æ•°é‡:")
        print(f"  - å…³é”®è¯: {len(test_queries['keyword'])}")
        print(f"  - è¯­ä¹‰: {len(test_queries['semantic'])}")
        print(f"  - æ··åˆ: {len(test_queries['mixed'])}")

        # 4. æµ‹è¯•ä¸åŒæƒé‡
        conv_results = {
            'conversation': test_queries['conversation'],
            'file': str(conv_file),
            'test_queries': test_queries,
            'weight_tests': []
        }

        for bm25_w in weight_candidates:
            print(f"\n[INFO] æµ‹è¯•æƒé‡é…æ¯” BM25:{bm25_w:.1f} Vector:{1-bm25_w:.1f}")

            test_result = test_weight_configuration(
                vector_store, embedding_client, test_queries, bm25_w
            )

            conv_results['weight_tests'].append(test_result)

            # ç´¯ç§¯ç»Ÿè®¡
            if 'avg_score_diff' in test_result['metrics']:
                all_results['weight_comparison'][bm25_w]['total_score_diff'] += test_result['metrics']['avg_score_diff']
                all_results['weight_comparison'][bm25_w]['count'] += 1

                print(f"  å¹³å‡åˆ†æ•°åŒºåˆ†åº¦: {test_result['metrics']['avg_score_diff']:.3f}")
                print(f"  æŸ¥è¯¢æ•°é‡: {test_result['metrics']['total_queries']}")

        all_results['conversations'].append(conv_results)

    # 5. æ±‡æ€»æœ€ä½³æƒé‡
    print(f"\n{'='*80}")
    print("æƒé‡ä¼˜åŒ–ç»“æœæ±‡æ€»")
    print(f"{'='*80}")

    best_weight = None
    best_score = -1

    for bm25_w in weight_candidates:
        stats = all_results['weight_comparison'][bm25_w]
        if stats['count'] > 0:
            avg_diff = stats['total_score_diff'] / stats['count']
            print(f"BM25:{bm25_w:.1f} Vector:{1-bm25_w:.1f} -> å¹³å‡åˆ†æ•°åŒºåˆ†åº¦: {avg_diff:.3f}")

            if avg_diff > best_score:
                best_score = avg_diff
                best_weight = bm25_w

    all_results['best_weight'] = {
        'bm25': best_weight,
        'vector': 1 - best_weight,
        'score': best_score
    }

    print(f"\nğŸ¯ æœ€ä½³æƒé‡é…æ¯”: BM25:{best_weight:.1f} Vector:{1-best_weight:.1f}")
    print(f"   å¹³å‡åˆ†æ•°åŒºåˆ†åº¦: {best_score:.3f}")

    # 6. ä¿å­˜ç»“æœ
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)

    print(f"\n[INFO] è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    return all_results

def main():
    # é€‰æ‹©æµ‹è¯•å¯¹è¯ï¼ˆ1000-2000æ¡æ¶ˆæ¯ï¼Œç±»å‹å¤šæ ·åŒ–ï¼‰
    test_conversations = [
        Path("chat_data_filtered/alex_li/alex_li.json"),      # å·¥ä½œ/æŠ€æœ¯ 1069æ¡
        Path("chat_data_filtered/å‘¨ä»•è¾¾/å‘¨ä»•è¾¾.json"),         # æ•™è‚²/å­¦ä¹  1008æ¡
        Path("chat_data_filtered/é»„å¿ƒæ€¡/é»„å¿ƒæ€¡.json"),         # å·¥ä½œè®¨è®º 1032æ¡
        Path("chat_data_filtered/é˜¡é™Œ/é˜¡é™Œ.json"),             # æ—¥å¸¸ç”Ÿæ´» 1080æ¡
    ]

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    valid_conversations = [c for c in test_conversations if c.exists()]

    if not valid_conversations:
        print("[ERROR] æœªæ‰¾åˆ°æµ‹è¯•å¯¹è¯æ–‡ä»¶")
        return

    print(f"[INFO] å°†æµ‹è¯• {len(valid_conversations)} ä¸ªå¯¹è¯")
    for conv in valid_conversations:
        print(f"  - {conv.parent.name}")

    # è¿è¡Œä¼˜åŒ–
    results = optimize_weights_for_conversations(valid_conversations)

if __name__ == "__main__":
    load_dotenv()
    main()
